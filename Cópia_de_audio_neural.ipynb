{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxBshJbX-rDj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting musdb\n",
      "  Using cached https://files.pythonhosted.org/packages/57/bd/98ba16482f610bcfa7fcc212175dc0bbf11976e0bc69319b4204b6dc3aec/musdb-0.3.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/lib64/python2.7/site-packages (from musdb) (1.15.1)\n",
      "Collecting tqdm (from musdb)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/80/5bb262050dd2f30f8819626b7c92339708fe2ed7bd5554c8193b4487b367/tqdm-4.42.1-py2.py3-none-any.whl\n",
      "Collecting stempeg>=0.1.7 (from musdb)\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/dc/b37d98b2532aadfbf941695d6663ff0b54103795223cea8c17bf91a55183/stempeg-0.1.8.tar.gz\n",
      "Collecting soundfile>=0.9.0 (from musdb)\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Collecting pyaml (from musdb)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/1e/eda9fe07f752ced7afcef590e7d74390f0d9c9c0b7ff98317afbaa0697e3/pyaml-19.12.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/lib64/python2.7/site-packages (from soundfile>=0.9.0->musdb) (1.11.5)\n",
      "Requirement already satisfied: PyYAML in /usr/lib64/python2.7/site-packages (from pyaml->musdb) (5.1)\n",
      "Requirement already satisfied: pycparser in /usr/lib/python2.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->musdb) (2.14)\n",
      "Installing collected packages: tqdm, soundfile, stempeg, pyaml, musdb\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permissão negada: '/usr/lib/python2.7/site-packages/tqdm-4.42.1.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python2.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/lib64/python2.7/site-packages (from keras) (1.15.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python2.7/site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz\n",
      "Collecting h5py (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/lib64/python2.7/site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras-preprocessing, h5py, keras-applications, keras\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permissão negada: '/usr/lib64/python2.7/site-packages/Keras_Preprocessing-1.1.0.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/59/d88fe8c58ffb66aca21d03c0e290cd68327cc133591130c674985e98a482/tensorflow-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/lib64/python2.7/site-packages (from tensorflow) (1.15.1)\n",
      "Collecting wheel (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/lib/python2.7/site-packages (from tensorflow) (2.0.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/68/eed71ec8e8383a43987e0a58492b0aa043dc29971cac59b8b1d1e7951123/google_pasta-0.1.8-py2-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/cc/9180fa1f97ad122d92cfbff413bcd0be4bd3efee284a5fb6344670220709/protobuf-3.11.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python2.7/site-packages (from tensorflow) (1.11.0)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/39/0379c2d3357451609cf3f8b711c87418f20b31d683856b503fd047b66468/grpcio-1.27.1-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: enum34>=1.1.6 in /usr/lib/python2.7/site-packages (from tensorflow) (1.1.6)\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: funcsigs>=1 in /usr/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow) (1.0.2)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python2.7/site-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: futures>=3.1.1; python_version < \"3\" in /usr/lib/python2.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.3.0)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "\u001b[31mpandas-datareader 0.6.0 requires requests-ftp, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 40.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, wrapt, astor, wheel, termcolor, google-pasta, gast, tensorflow-estimator, protobuf, h5py, keras-applications, absl-py, grpcio, werkzeug, markdown, tensorboard, backports.weakref, tensorflow\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permissão negada: '/usr/lib64/python2.7/site-packages/Keras_Preprocessing-1.1.0.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\r\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "!pip install musdb\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "bMYFauN4_fqv",
    "outputId": "c5173905-6048-46ce-be28-a350a4391b07"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-59f131bd6e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from google.colab import drive\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VqvvfLBK-3HH",
    "outputId": "e5e54919-881b-458f-eed2-65acdd808a3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "/device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.path = '/content/drive/My Drive/Projeto Final/'\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load(self.path + 'data_samples/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = np.load(self.path + 'vocal_samples/' + ID + '.npy')\n",
    "\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z-qlZAZfLwoP",
    "outputId": "bde242fe-398d-4c09-f5fe-215b7ca4fdce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHjdMywvLaUq"
   },
   "outputs": [],
   "source": [
    "range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJmeQ0DsD6on"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(16, (3,3), padding='same', input_shape=(513, 11, 1)))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Conv2D(16, (3,3), padding='same'))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv2D(16, (3,3), padding='same'))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Conv2D(16, (3,3), padding='same'))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(513, activation='relu'))\n",
    "  model.compile(loss=keras.losses.mse, optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Vm9fgNZEIw3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnPXsFAI_GAJ"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "  model.fit(np.abs(train_data_groups).reshape(target_groups.shape[0],513,11,1),np.abs(target_groups),batch_size = 32,epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5bQx4qlAISj"
   },
   "outputs": [],
   "source": [
    "a = model.predict(np.abs(train_data_groups[0:1*1293].reshape(1293,513,25,1)))\n",
    "test = np.transpose(a)\n",
    "test_list = []\n",
    "for i in range(len(test)):\n",
    "  test_list.append(np.roll(test[i],2))\n",
    "test = np.array(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXRD0-Wj5Prs"
   },
   "outputs": [],
   "source": [
    "vocal_stft_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xiKu0n1_2-w"
   },
   "outputs": [],
   "source": [
    "result_stft = np.multiply(test,stft_list[0])\n",
    "plt.pcolormesh(t, f, np.abs(result_stft))\n",
    "xmin =0\n",
    "xmax = 1\n",
    "ymin =0\n",
    "ymax = 3000\n",
    "\n",
    "plt.axis([xmin, xmax, ymin, ymax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D6LZw6GFp9I"
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(t, f, np.abs(vocal_stft_list[0]))\n",
    "xmin =0\n",
    "xmax = 1\n",
    "ymin =0\n",
    "ymax = 3000\n",
    "\n",
    "plt.axis([xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0yGidBR6rXQ"
   },
   "outputs": [],
   "source": [
    "audio1 = signal.istft(result_stft,fs =mus[0].rate)\n",
    "audio1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBLni4gQ7Hxx"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(audio1[1],rate=mus[0].rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6eoYANz-zgY"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(mus[0].audio[:,0] + mus[0].audio[:,1],rate=mus[0].rate)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Cópia de audio_neural.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
